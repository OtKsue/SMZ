{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as func"
      ],
      "metadata": {
        "id": "DFyIwcucMwPX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAQfSYAnEG47",
        "outputId": "bd36eb9f-0d7c-4a0c-c905-fc1026dd61ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: (1, 5, 5, 3)\n",
            "Weight shape: (3, 3, 3, 2)\n",
            "Output shape: (1, 3, 3, 2)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def convolution_transpose(input, filter, stride=1, padding=0):\n",
        "    batch_size, in_height, in_width, in_channels = input.shape\n",
        "    filter_height, filter_width, in_channels, out_channels = filter.shape\n",
        "\n",
        "    # Calculate output tensor dimensions\n",
        "    output_height = (in_height - 1) * stride - 2 * padding + filter_height\n",
        "    output_width = (in_width - 1) * stride - 2 * padding + filter_width\n",
        "\n",
        "    # Create output tensor\n",
        "    output = np.zeros((batch_size, output_height, output_width, out_channels))\n",
        "\n",
        "    # Transposed convolution\n",
        "    for b in range(batch_size):\n",
        "        for c in range(out_channels):\n",
        "            for i in range(in_channels):\n",
        "                for h in range(output_height):\n",
        "                    for w in range(output_width):\n",
        "                        for kh in range(filter_height):\n",
        "                            for kw in range(filter_width):\n",
        "                                ih = h * stride + kh - padding\n",
        "                                iw = w * stride + kw - padding\n",
        "                                if 0 <= ih < in_height and 0 <= iw < in_width:\n",
        "                                    output[b, h, w, c] += input[b, ih, iw, i] * filter[kh, kw, i, c]\n",
        "    return output\n",
        "\n",
        "# Example usage\n",
        "input_tensor = np.random.randn(1, 5, 5, 3)\n",
        "weight_tensor = np.random.randn(3, 3, 3, 2)\n",
        "padding = 1\n",
        "stride = 2\n",
        "output_tensor = convolution_transpose(input_tensor, weight_tensor, padding, stride)\n",
        "\n",
        "print(\"Input shape:\", input_tensor.shape)\n",
        "print(\"Weight shape:\", weight_tensor.shape)\n",
        "print(\"Output shape:\", output_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание тестовых данных\n",
        "input_tensor = np.random.rand(1, 3, 5, 5)\n",
        "weight_tensor = np.random.rand(3, 4, 3, 3)\n",
        "bias_tensor = np.random.rand(4)\n",
        "\n",
        "# Получение выходного тензора\n",
        "output_tensor = convolution_transpose(input_tensor, weight_tensor, padding, stride)\n",
        "\n",
        "# Проверка размеров выходного тензора\n",
        "assert output_tensor.shape == (1, 1, 4, 3), f\"{output_tensor.shape}\"\n",
        "\n",
        "# Проверка, что выходной тензор не является нулевым\n",
        "assert np.any(output_tensor != 0)"
      ],
      "metadata": {
        "id": "26b1DUMNEK4y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание тестовых данных\n",
        "input_tensor = np.random.rand(1, 3, 5, 5)\n",
        "weight_tensor = np.random.rand(3, 4, 3, 3)\n",
        "\n",
        "# Установка параметров свертки\n",
        "stride = 2\n",
        "padding = 1\n",
        "\n",
        "# Создание случайного bias\n",
        "bias_tensor = np.random.rand(4)\n",
        "\n",
        "# Получение выходного тензора\n",
        "output_tensor = convolution_transpose(input_tensor, weight_tensor, padding, stride)\n",
        "\n",
        "# Проверка размеров выходного тензора\n",
        "assert output_tensor.shape == (1, 1, 4, 3), f\"{output_tensor.shape}\""
      ],
      "metadata": {
        "id": "qOVnSQSXJ2Mw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание тестовых данных\n",
        "input_tensor = np.random.rand(2, 3, 5, 5)\n",
        "weight_tensor = np.random.rand(3, 4, 3, 3)\n",
        "\n",
        "# Вычисление выходного тензора с помощью функции convolution_transpose\n",
        "output_tensor = convolution_transpose(input_tensor, weight_tensor, padding, stride)\n",
        "\n",
        "# Создание нового входного тензора из выходного тензора\n",
        "input_tensor_new = convolution_transpose(output_tensor, weight_tensor)\n",
        "\n",
        "# Проверка, что новый входной тензор исходный входной тензор\n",
        "print(\"Shape of input_tensor:\", input_tensor.shape)\n",
        "print(\"Shape of input_tensor_new:\", input_tensor_new.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOv-7d0-Khk-",
        "outputId": "f9e56918-be7b-41cf-a55a-2ff1b0c17e53"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of input_tensor: (2, 3, 5, 5)\n",
            "Shape of input_tensor_new: (2, 3, 7, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание тестовых данных\n",
        "input_tensor = np.random.rand(2, 3, 5, 5)\n",
        "weight_tensor = np.random.rand(3, 4, 3, 3)\n",
        "\n",
        "# Получение выходного тензора\n",
        "output_tensor = convolution_transpose(input_tensor, weight_tensor)\n",
        "\n",
        "# Проверка размеров выходного тензора\n",
        "assert output_tensor.shape == (2, 5, 8, 3), f\"{output_tensor.shape}\""
      ],
      "metadata": {
        "id": "s4PvknmaLfgf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дополнительное задание"
      ],
      "metadata": {
        "id": "acRZpL1arizy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def my_custom_conv2d(my_input, my_weight, my_bias=None, my_stride=1, my_padding=0, my_dilation=1):\n",
        "    # Extract input and weight dimensions\n",
        "    batch_size, input_channels, height_in, width_in = my_input.shape\n",
        "    out_channels, in_channels, kernel_height, kernel_width = my_weight.shape\n",
        "\n",
        "    # Compute output dimensions\n",
        "    height_out = (height_in + 2 * my_padding - my_dilation * (kernel_height - 1) - 1) // my_stride + 1\n",
        "    width_out = (width_in + 2 * my_padding - my_dilation * (kernel_width - 1) - 1) // my_stride + 1\n",
        "\n",
        "    # Initialize output tensor with zeros\n",
        "    my_output = torch.zeros((batch_size, out_channels, height_out, width_out))\n",
        "\n",
        "    # Pad input tensor with zeros\n",
        "    padded_input = F.pad(my_input, (my_padding, my_padding, my_padding, my_padding))\n",
        "\n",
        "    # Iterate over the input dimensions and compute output\n",
        "    for b in range(batch_size):\n",
        "        for oc in range(out_channels):\n",
        "            for h_out in range(height_out):\n",
        "                for w_out in range(width_out):\n",
        "                    # Extract patch from padded input\n",
        "                    h_start = h_out * my_stride\n",
        "                    w_start = w_out * my_stride\n",
        "                    h_end = h_start + my_dilation * (kernel_height - 1) + 1\n",
        "                    w_end = w_start + my_dilation * (kernel_width - 1) + 1\n",
        "                    patch = padded_input[b, :, h_start:h_end:my_dilation, w_start:w_end:my_dilation]\n",
        "\n",
        "                    # Perform element-wise multiplication of the patch with the weight tensor\n",
        "                    output_patch = patch * my_weight[oc]\n",
        "\n",
        "                    # Compute the sum along all the input channels\n",
        "                    output_patch_sum = output_patch.sum(dim=1, keepdim=True)\n",
        "\n",
        "                    # Sum the results from all input channels\n",
        "                    my_output[b, oc, h_out, w_out] = output_patch_sum.sum()\n",
        "\n",
        "                    # Add bias if provided\n",
        "                    if my_bias is not None:\n",
        "                        my_output[b, oc, h_out, w_out] += my_bias[oc]\n",
        "\n",
        "    return my_output"
      ],
      "metadata": {
        "id": "_Uv8XldBrd6_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_test_data():\n",
        "    input_data = torch.randn(1, 1, 4, 4)\n",
        "    weight_data = torch.randn(1, 1, 3, 3)\n",
        "    output = my_custom_conv2d(input_data, weight_data)\n",
        "    print(\"Test 'generate_test_data' passed!\")\n",
        "    return output\n",
        "\n",
        "def test_convolution2d():\n",
        "    input_data = torch.randn(1, 1, 10, 10)\n",
        "    weight_data = torch.randn(1, 1, 3, 3)\n",
        "    output = my_custom_conv2d(input_data, weight_data)\n",
        "    print(\"Test 'test_convolution2d' passed!\")\n",
        "    return output\n",
        "\n",
        "def test_convolution2d_kernel():\n",
        "    input_data = torch.randn(2, 3, 4, 4)\n",
        "    weight_data = torch.randn(2, 3, 3, 3)\n",
        "    output = my_custom_conv2d(input_data, weight_data)\n",
        "    print(\"Test 'test_convolution2d_kernel' passed!\")\n",
        "    return output\n",
        "\n",
        "def test_convolution2d_image():\n",
        "    input_data = torch.randn(1, 1, 10, 10)\n",
        "    weight_data = torch.randn(1, 1, 10, 10)\n",
        "    output = my_custom_conv2d(input_data, weight_data)\n",
        "    print(\"Test 'test_convolution2d_image' passed!\")\n",
        "    return output"
      ],
      "metadata": {
        "id": "cxSsqsPwxuft"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_test_data()\n",
        "test_convolution2d()\n",
        "test_convolution2d_kernel()\n",
        "test_convolution2d_image()"
      ],
      "metadata": {
        "id": "hNogY6z_yBiq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c15ae549-cab3-4553-823b-c226c9d5c073"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test 'generate_test_data' passed!\n",
            "Test 'test_convolution2d' passed!\n",
            "Test 'test_convolution2d_kernel' passed!\n",
            "Test 'test_convolution2d_image' passed!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[-1.7601]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6A23KpkqHozy"
      },
      "execution_count": 18,
      "outputs": []
    }
  ]
}